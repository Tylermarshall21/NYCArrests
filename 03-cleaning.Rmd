# Data transformation

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=FALSE)
library(tidyverse)
library(lubridate)
```

## Arrest Data

### Data Import - 2021 Data

We begin by importing our data source as-is. This will give us a starting point for our data adjustment and cleaning. We save this data as 'nyc_arrests'.

```{r}
nyc_arrests <- read.table("https://data.cityofnewyork.us/api/views/uip8-fykc/rows.csv?accessType=DOWNLOAD",
                          header=TRUE,
                          sep=",",
                          quote='"'
                          )
```

For easier use of the dates associated with the arrests, we will convert these into R-compatible dates. We will also remove several columns not necessary for the analysis.

```{r}
nyc_arrests$ARREST_DATE <- as_date(nyc_arrests$ARREST_DATE, format="%m/%d/%Y")
nyc_arrests <- nyc_arrests %>% select(-c(New.Georeferenced.Column, X_COORD_CD, Y_COORD_CD))
```

### Data Import - 2006-2021 Data

We now repeat this transformation on our older data. We save this data as 'nyc_arrests_old'. One issue with this dataset is its size. Weighing in at over one Gigabyte, this dataset in its unmodified form takes a very long time to download and modify. As a result, we have decided to utilize a reduced version of this dataset that only includes data starting in 2011. The transformations used to create this historical dataset are seen below:

```{r, eval=FALSE}
nyc_arrests <- read.table("D:/Documents/R Projects/Final Project Proposal/NYPD_Arrests_Data__Historic_.csv",
                           header=TRUE,
                           sep=",",
                           quote='"'
)

nyc_arrests <- nyc_arrests %>% select(-c(Lon_Lat, X_COORD_CD, Y_COORD_CD))

nyc_arrests$ARREST_DATE <- as_date(nyc_arrests$ARREST_DATE, format="%m/%d/%Y")

nyc_arrests <- filter(nyc_arrests, ARREST_DATE > "2010-12-31")

write.csv(nyc_arrests, file="nyc_arrests_post2010.csv")
```

We then run a matching set of data transformations.

```{r}
nyc_arrests_old <- read.table("nyc_arrests_post2010.csv",
                          header=TRUE,
                          sep=",",
                          quote='"'
                          )
nyc_arrests_old <- nyc_arrests_old %>% select(-c(X))
nyc_arrests_old$ARREST_DATE <- as_date(nyc_arrests_old$ARREST_DATE, format="%Y-%m-%d")
```

### Combining Old and New

For a lot of our analysis we will want a combined dataset, so we can append the historical data to the 2021 data like so:

```{r}
nyc_arrests_combined <- bind_rows(nyc_arrests, nyc_arrests_old)
```

This is the main dataset we will be using throughout our analysis, but for certain visualizations we will want our data by category of arrest. The transformation to get the data in that form is below.

### Aggregating by Category

For many of our analyses, it is sensible to aggregate crime by its rough category, like so:

```{r}
nyc_arrests_by_category_year_boro <- (
  nyc_arrests_combined %>%
    drop_na(OFNS_DESC) %>%
    filter(OFNS_DESC != "", ARREST_BORO != "") %>%
    mutate(ARREST_YEAR = year(ARREST_DATE)) %>%
    group_by(ARREST_YEAR, OFNS_DESC, ARREST_BORO) %>%
    summarize(COUNT_OF_ARRESTS = n())
)
```

## Crime Data

The other dataset that we will be using in our analysis is a dataset looking at crime in New York. This dataset gives aggregated crime numbers for each New York county, and this data is from 2010-2020. We will be using this to compare to arrest levels in our analysis, so we did the following transformation below to get data by borough.

```{r}
# Crime Data Import
nyc_crime <- read.table("https://data.ny.gov/api/views/ca8h-8gjq/rows.csv?accessType=DOWNLOAD&sorting=true",
                        header=TRUE,
                        sep=",",
                        quote='"'
                        )

nyc_crime <- (
  filter(nyc_crime, Region == "New York City", Year > 2010) %>%
    select(c(County, Year, Murder, Rape, Aggravated.Assault, Motor.Vehicle.Theft)) %>%
    mutate(Category = "Crime Reports")
)
```

## Interactive Component

Some data was assembled and formatted for use in our interactive visual. This included a list of the top 100 days with the most arrests and weather in NYC.

### Top 100 Days

First, we assembled the top 100 days with the highest arrests and stored this as a dataframe.

```{r}
nyc_arrest_top_hundred <- nyc_arrests_combined %>%
  mutate(Weekday = wday(ARREST_DATE)) %>%
  group_by(ARREST_DATE, Weekday) %>%
  summarize(Number_Arrests = n()) %>%
  ungroup() %>%
  arrange(desc(Number_Arrests)) %>%
  mutate(ARREST_YEAR = year(ARREST_DATE),
         ARREST_MONTH = month(ARREST_DATE),
         ARREST_MONTH_TEXT = month(ARREST_DATE)) %>%
  slice(1:100)

nyc_arrest_top_hundred$Weekday <- factor(nyc_arrest_top_hundred$Weekday,
                                     levels= c(1,2,3,4,5,6,7),
                                     labels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday","Friday","Saturday")
                                     )
nyc_arrest_top_hundred$ARREST_MONTH_TEXT <- factor(nyc_arrest_top_hundred$ARREST_MONTH_TEXT,
                                                   levels= c(1,2,3,4,5,6,7,8,9,10,11,12),
                                                   labels=c("January",
                                                            "February",
                                                            "March",
                                                            "April",
                                                            "May",
                                                            "June",
                                                            "July",
                                                            "August",
                                                            "September",
                                                            "October",
                                                            "November",
                                                            "December")
                                                   )


```


### Weather Data

Our weather data was stored in csv files, which we then transformed to form a cleaner data set. In our original dataset, there were some values marked as T, representing precipitation less than 0.01 inches. For the sake of simplicity, we translated 'Trace' precipitation as 0.001. This will show that there was precipitation less than the threshold of 0.01, while not overstating the quantity of rain. For our uses, this will not make the data misleading when presented. On days where equipment malfunctioned, we set the value to NA.

```{r}
# Precipitation Data Import
nyc_weather <- read.table("./Precip_Data.csv",
                        header=TRUE,
                        sep=",",
                        quote='"'
                        )

nyc_weather <- (
  nyc_weather %>%
    pivot_longer(cols = !Day,
                 names_to = "Month",
                 values_to = "Precipitation"
                 ) %>%
    unite(Date, c(Month, Day))
)

nyc_weather$Date <- as_date(nyc_weather$Date, format="%b.%y_%d")

nyc_temp <- read.table("./Temp_Data.csv",
                        header=TRUE,
                        sep=",",
                        quote='"'
                        )

nyc_temp <- (
  nyc_temp %>%
    pivot_longer(cols = !Day,
                 names_to = "Month",
                 values_to = "Mean_Temperature"
                 ) %>%
    unite(Date, c(Month, Day))
)

nyc_temp$Date <- as_date(nyc_temp$Date, format="%b.%y_%d")

nyc_weather <- full_join(nyc_weather, nyc_temp)
```

### Combining Weather and Top 100

A simple join combines the two datasets, which are then stored as a file.

```{r}
combined_hundred <- left_join(nyc_arrest_top_hundred, nyc_weather, by = c("ARREST_DATE" = "Date"))

combined_hundred$Ranking <- 1:nrow(combined_hundred)

write.csv(combined_hundred, file="interactive_testing/tophundred.csv")
```

