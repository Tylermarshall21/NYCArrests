# Missing values

```{r, include=FALSE}
library(tidyverse)
library(patchwork)
library(lubridate)
library(kableExtra)
```

```{r, echo = FALSE}
visna_na_plot <-
  function(dataset,percent=FALSE){
    missing_patterns <- data.frame(is.na(dataset)) %>%
      group_by_all() %>%
      count(name = "count", sort = TRUE) %>%
      ungroup() %>%
      mutate(percentage = (count / sum(count)) * 100)

    dataset_nulls <- {
      colSums(is.na(dataset)) %>%
        sort(decreasing = TRUE)
    }
    df_null <- {
      data.frame(dataset_nulls) %>%
        rownames_to_column() %>%
        mutate(percentage = (dataset_nulls / nrow(dataset)) * 100)
    }
    
    missing_patterns['pattern'] <- as.integer(row.names(missing_patterns))
    
    missing_patterns_p2 <-{
      missing_patterns %>%
        rowwise() %>%
        mutate(is_complete = !any(c_across(where(is.logical))))
    }
    
    if(percent == FALSE){
      p3 <- {
        ggplot(missing_patterns_p2, aes(y = reorder(pattern, desc(pattern)), x = count, alpha = is_complete)) + 
          geom_col(fill="blue") +
          labs(x = 'Row Count', y = '') +
          theme(legend.position = 'none', axis.text.x = element_text(angle=90, hjust = 1)) +
          scale_alpha_manual(values = c(0.5, 1))
      }
    }else{
      p3 <- {
        ggplot(missing_patterns_p2, aes(y = reorder(pattern, desc(pattern)), x = percentage, alpha = is_complete)) + 
          geom_col(fill="blue") +
          xlim(0,100) +
          labs(x = '% Rows', y = '') +
          theme(legend.position = 'none', axis.text.x = element_text(angle=90, hjust = 1)) +
          scale_alpha_manual(values = c(0.5, 1))
      }
    }
    
    
    missing_patterns_pivoted <- {
      missing_patterns_p2 %>%
        pivot_longer(cols = !c(count, percentage, pattern, is_complete)) %>%
        left_join(df_null, by= c('name'='rowname'))
    }
    
    p2 <- {
      ggplot(missing_patterns_pivoted,
             aes(
               x = reorder(name, desc(dataset_nulls)),
               y = reorder(pattern, desc(pattern)),
               fill = value,
               alpha = is_complete)) +
        geom_tile(color = 'white') +
        annotate("text",
                 x = (ncol(missing_patterns_p2)-2)/2,
                 y = (nrow(missing_patterns_p2) - as.integer(filter(missing_patterns_p2, is_complete)['pattern'][[1]]) + 1),
                 label = 'Complete Cases') +
        labs(x = 'Variable', y = 'Missing Pattern') +
        theme(legend.position = 'none', axis.text.x = element_text(angle=90, hjust = 1)) +
        scale_alpha_manual(values = c(0.5, 1)) +
        scale_fill_manual(values = c("gray", "blue"))
    }
    if(percent == FALSE){
      p1 <- {
        ggplot(df_null, aes(reorder(rowname,-dataset_nulls),dataset_nulls,alpha = 0.5)) +
          geom_col(fill='blue') +
          labs(x = '',y = 'Rows Missing') +
          theme(legend.position = 'none', axis.text.x = element_text(angle=90, hjust = 1))
      }
    }else{
      p1 <- {
        ggplot(df_null, aes(reorder(rowname,-percentage),percentage,alpha = 0.5)) +
          geom_col(fill='blue') +
          ylim(0,100) +
          labs(x = '',y = '% Rows Missing') +
          theme(legend.position = 'none', axis.text.x = element_text(angle=90, hjust = 1))
      }
    }
    
    p1 + plot_spacer() + p2 + p3 + plot_layout(widths = c(5, 1), heights = c(1, 5))
  }
```


```{r, echo = FALSE}
nyc_arrests <- read.table("https://data.cityofnewyork.us/api/views/uip8-fykc/rows.csv?accessType=DOWNLOAD",
                          header=TRUE,
                          sep=",",
                          quote='"'
                          )
nyc_arrests$ARREST_DATE <- as_date(nyc_arrests$ARREST_DATE, format="%m/%d/%Y")
nyc_arrests <- nyc_arrests %>% select(-c(New.Georeferenced.Column, X_COORD_CD, Y_COORD_CD))
nyc_arrests_old <- read.table("nyc_arrests_post2010.csv",
                          header=TRUE,
                          sep=",",
                          quote='"'
                          )
nyc_arrests_old <- nyc_arrests_old %>% select(-c(X))
nyc_arrests_old$ARREST_DATE <- as_date(nyc_arrests_old$ARREST_DATE, format="%Y-%m-%d")
nyc_arrests_combined <- bind_rows(nyc_arrests, nyc_arrests_old)
```


## Investigating Missing Values

The main dataset for our project is data on New York City arrests. For this particular analysis, we will focus only on the NYC arrest data for the past 10 years which is what we will be using for our analysis. Before visualizing our missing values, however, we noticed that some of the entries in the data had empty strings (""), but were not classified as NA in the dataset. Since we felt these empty strings were the equivalent of NA, we changed them in our dataset before plotting the missing values.

```{r missing values 1, echo = FALSE}
#First replace "" with NA
nyc_arrests_combined2 <- nyc_arrests_combined %>%
  na_if("")
#Abbreviate names to make it easier to read
names(nyc_arrests_combined2) <- abbreviate(names(nyc_arrests_combined2),minlength=3)
#Plot NA patterns
visna_na_plot(nyc_arrests_combined2)
```

From the first plot, we can see that there are 6 different patterns in our data with the most common pattern being no missing data. The plot above shows that there isn't too much missing data in our dataset, but there are still a few variables that had missing values. The most common pattern where there was missing data is for just `LAW_CA` to be missing, and this happened around 15000 times in our dataset. `LAW_CA` is the level of the offense (felony, misdemeanor or violation), so it seems this is not always documented when the arrest occurs. The second most common pattern where data was missing was for the data to be missing `KY_`, `OFN`, and `PD_D`. This pattern was far less common and occurred around 5000 times out of over 3.2 million observations in the data. `KY_` is an internal classification keycode,  `OFN` is a description of internal classification, and `PD_D` is a description of internal classification that is more granular than `OFN`. It seems that on occasion these codes and descriptions were not filled in when the arrest was made. The next most common pattern contains `KY_`, `OFN`, `PD_D` again, but also contains `PD_C`. `PD_C` is another internal classification code that is more granular than `KY_`. This pattern is very similar to previous one, but contains another missing variable that is similar to the others. The next most common missing patterns has the most missing variables with `LAW_CA`, `KY_`, `OFN`, `PD_D`, `PD_C`, `LAW_CO` all missing. `LAW_CO` is the only variable in this group that hadn't been in another pattern and this variable represents the law code charges which is a classification code to indicate the charge of the arrest. Our final missing pattern only had `ARREST_B` variable which is the borough that the arrest occurred in. This pattern was not very common which indicates that the arrest records do a good job keeping track of the location where the arrest happened. We also want to plot our missing data showing percentage missing instead of number of rows missing.

```{r missing values 2, echo = FALSE}
#Plot NA patterns with percentages
visna_na_plot(nyc_arrests_combined2, percent = TRUE)
```

The patterns are the same as the plot above, but this plot emphasizes the limited amount of missing data in our dataset. The portion of missing data is very small for our dataset, which is a good sign for our analysis. If there is too much missing data, the analysis can be much more challenging, but this is not the case with the NYC arrests data.

Before moving on to the results section, we wanted to look further into the missing values in our dataset to see if there were any patterns with values of other variables. 

```{r, echo = FALSE}
nyc_arrests_missing <- nyc_arrests_combined2[rowSums(is.na(nyc_arrests_combined2)) > 0,]
nyc_arrests_missing2 <- nyc_arrests_missing %>%
  group_by(ARREST_P) %>%
  summarize(Number_Missing = n())

nyc_arrests_missing3 <- nyc_arrests_missing %>%
  group_by(ARREST_B) %>%
  summarize(Number_Missing = n())
nyc_arrests_combined3 <- nyc_arrests_combined2 %>%
  group_by(ARREST_B) %>%
  summarize(Total = n())
nyc_arrests_combined4 <- nyc_arrests_combined2 %>%
  group_by(ARREST_P) %>%
  summarize(Total = n())
nyc_arrests_borough <- inner_join(nyc_arrests_missing3, nyc_arrests_combined3, by = "ARREST_B")
nyc_arrests_borough2 <- nyc_arrests_borough %>%
  mutate(PCT_Missing = Number_Missing/Total)
nyc_arrests_precinct <- inner_join(nyc_arrests_missing2, nyc_arrests_combined4, by = "ARREST_P")
nyc_arrests_precinct2 <- nyc_arrests_precinct %>%
  mutate(PCT_Missing = Number_Missing/Total)

nyc_arrests_borough2 %>%
  arrange(desc(PCT_Missing)) %>%
  kable(align = "c") %>%
  kable_styling(position = "center", latex_options=c('striped', 'hold_position'))


```

We wanted to look to see if there were any patterns of missing data in terms of location of the arrest. We started by looking at the borough that the arrest occurred in to see if certain boroughs had more missing data than others. We found that Manhattan had the largest percentage of arrests with at least missing values, but still only 1 percent of Manhattan arrests were missing data. There was missing data in .7 percent of Bronx arrests and .6 percent of Queens arrests. Staten Island and Brooklyn had the lowest percent of arrests with missing data with only .3 percent. There is some small difference in missing data by borough, but does not seem to be a clear pattern in terms of the borough the arrest occurred in.

```{r, echo = FALSE}
nyc_arrests_precinct2 %>%
  arrange(desc(PCT_Missing)) %>%
  head(5) %>%
  kable(align = "c") %>%
  kable_styling(position = "center", latex_options=c('striped', 'hold_position'))
```

We also wanted to look to see if any precincts had more missing data than others. There were 77 different precincts in the dataset and the percentage of missing data ranged from 6 percent to .09 percent. The precinct with the highest proportion of missing data was precinct 5 while precincts 100 and 22 had the lowest proportion of missing data. Precinct 10 was missing data on 5.9 percent of its arrest which was the second highest, but precincts 5 and 10 were the only ones with more than 2.5 percent of entries missing data. Thus, it seems there does seem to be a few precincts that are much more likely to have missing data compared to others. Now that we have looked into our missing data, we are going to move on to analyzing our data in the results section.